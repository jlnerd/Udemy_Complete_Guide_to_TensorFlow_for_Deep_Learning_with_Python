{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise - Solutions\n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop(['medianHouseValue'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,y_val,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.069688</td>\n",
       "      <td>0.117163</td>\n",
       "      <td>0.048769</td>\n",
       "      <td>0.115442</td>\n",
       "      <td>0.142508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.015673</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7812</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.212866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.032530</td>\n",
       "      <td>0.033830</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.030094</td>\n",
       "      <td>0.298651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.031919</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.019466</td>\n",
       "      <td>0.034863</td>\n",
       "      <td>0.272631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16312</th>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.113739</td>\n",
       "      <td>0.144010</td>\n",
       "      <td>0.076112</td>\n",
       "      <td>0.145206</td>\n",
       "      <td>0.192342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.031789</td>\n",
       "      <td>0.066436</td>\n",
       "      <td>0.207783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.048298</td>\n",
       "      <td>0.045624</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.057721</td>\n",
       "      <td>0.346181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061015</td>\n",
       "      <td>0.053538</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>0.053774</td>\n",
       "      <td>0.436704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20441</th>\n",
       "      <td>0.450980</td>\n",
       "      <td>0.103515</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>0.064104</td>\n",
       "      <td>0.092748</td>\n",
       "      <td>0.382671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13243</th>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.098555</td>\n",
       "      <td>0.075885</td>\n",
       "      <td>0.063439</td>\n",
       "      <td>0.080414</td>\n",
       "      <td>0.550613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6450</th>\n",
       "      <td>0.843137</td>\n",
       "      <td>0.050994</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.050321</td>\n",
       "      <td>0.420615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10229</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.023628</td>\n",
       "      <td>0.043141</td>\n",
       "      <td>0.027133</td>\n",
       "      <td>0.049663</td>\n",
       "      <td>0.148715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.046569</td>\n",
       "      <td>0.054935</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>0.054761</td>\n",
       "      <td>0.212149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.044356</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>0.040122</td>\n",
       "      <td>0.068081</td>\n",
       "      <td>0.120695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.023068</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.013759</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.108874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.070934</td>\n",
       "      <td>0.076195</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.071863</td>\n",
       "      <td>0.190273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14741</th>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.069230</td>\n",
       "      <td>0.087834</td>\n",
       "      <td>0.077373</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.231238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18381</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.027417</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>0.013269</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>0.591723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.045577</td>\n",
       "      <td>0.067349</td>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.052744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.070019</td>\n",
       "      <td>0.078678</td>\n",
       "      <td>0.071526</td>\n",
       "      <td>0.080086</td>\n",
       "      <td>0.324375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040923</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.019361</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.568806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.108627</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.081399</td>\n",
       "      <td>0.131557</td>\n",
       "      <td>0.196170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14309</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.024087</td>\n",
       "      <td>0.026805</td>\n",
       "      <td>0.082440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.163869</td>\n",
       "      <td>0.285227</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.285150</td>\n",
       "      <td>0.143736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17197</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.050435</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>0.038126</td>\n",
       "      <td>0.089952</td>\n",
       "      <td>0.135874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.020932</td>\n",
       "      <td>0.027623</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.045786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15638</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091459</td>\n",
       "      <td>0.156735</td>\n",
       "      <td>0.072086</td>\n",
       "      <td>0.158691</td>\n",
       "      <td>0.171529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18035</th>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.033364</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.337319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.059871</td>\n",
       "      <td>0.062694</td>\n",
       "      <td>0.032139</td>\n",
       "      <td>0.058707</td>\n",
       "      <td>0.449966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.044693</td>\n",
       "      <td>0.033155</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.154343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.084923</td>\n",
       "      <td>0.122284</td>\n",
       "      <td>0.058887</td>\n",
       "      <td>0.123335</td>\n",
       "      <td>0.220252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6383</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.099344</td>\n",
       "      <td>0.113439</td>\n",
       "      <td>0.058992</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>0.280175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.044356</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.016938</td>\n",
       "      <td>0.297810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.044382</td>\n",
       "      <td>0.024297</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.199804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191</th>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.148045</td>\n",
       "      <td>0.072191</td>\n",
       "      <td>0.161322</td>\n",
       "      <td>0.187301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15436</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.111857</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.066450</td>\n",
       "      <td>0.120704</td>\n",
       "      <td>0.216383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12170</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.122005</td>\n",
       "      <td>0.160459</td>\n",
       "      <td>0.068725</td>\n",
       "      <td>0.155073</td>\n",
       "      <td>0.111605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.067704</td>\n",
       "      <td>0.100869</td>\n",
       "      <td>0.054266</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.216238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.144010</td>\n",
       "      <td>0.062283</td>\n",
       "      <td>0.149482</td>\n",
       "      <td>0.057447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17657</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.034485</td>\n",
       "      <td>0.061339</td>\n",
       "      <td>0.385767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.053233</td>\n",
       "      <td>0.083023</td>\n",
       "      <td>0.064944</td>\n",
       "      <td>0.074988</td>\n",
       "      <td>0.176163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18491</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.079302</td>\n",
       "      <td>0.106145</td>\n",
       "      <td>0.083325</td>\n",
       "      <td>0.111824</td>\n",
       "      <td>0.210701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.054159</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>0.050485</td>\n",
       "      <td>0.287624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>0.274510</td>\n",
       "      <td>0.038939</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>0.047032</td>\n",
       "      <td>0.142246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12911</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.079149</td>\n",
       "      <td>0.066574</td>\n",
       "      <td>0.039142</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>0.396139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.024009</td>\n",
       "      <td>0.058038</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.057721</td>\n",
       "      <td>0.087937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19566</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.088891</td>\n",
       "      <td>0.137492</td>\n",
       "      <td>0.086265</td>\n",
       "      <td>0.134024</td>\n",
       "      <td>0.099619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13020</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.046823</td>\n",
       "      <td>0.042210</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>0.045223</td>\n",
       "      <td>0.273762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.049193</td>\n",
       "      <td>0.031019</td>\n",
       "      <td>0.048183</td>\n",
       "      <td>0.296079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.053436</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>0.035570</td>\n",
       "      <td>0.063476</td>\n",
       "      <td>0.171805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17357</th>\n",
       "      <td>0.392157</td>\n",
       "      <td>0.054148</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.038196</td>\n",
       "      <td>0.057885</td>\n",
       "      <td>0.287231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20463</th>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.088840</td>\n",
       "      <td>0.069522</td>\n",
       "      <td>0.056927</td>\n",
       "      <td>0.070219</td>\n",
       "      <td>0.366181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12363</th>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.233150</td>\n",
       "      <td>0.234482</td>\n",
       "      <td>0.134265</td>\n",
       "      <td>0.208683</td>\n",
       "      <td>0.262838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16983</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.021570</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.367043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.043028</td>\n",
       "      <td>0.074494</td>\n",
       "      <td>0.288637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8006</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.014459</td>\n",
       "      <td>0.025654</td>\n",
       "      <td>0.285720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17745</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.089628</td>\n",
       "      <td>0.086592</td>\n",
       "      <td>0.048139</td>\n",
       "      <td>0.080579</td>\n",
       "      <td>0.389402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.021110</td>\n",
       "      <td>0.032588</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>0.191818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13151</th>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.085381</td>\n",
       "      <td>0.112353</td>\n",
       "      <td>0.065084</td>\n",
       "      <td>0.106890</td>\n",
       "      <td>0.149791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14448 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "6761           0.352941    0.069688       0.117163    0.048769    0.115442   \n",
       "3010           0.607843    0.011242       0.015673    0.008367    0.014142   \n",
       "7812           0.666667    0.025230       0.031347    0.020971    0.030258   \n",
       "8480           0.666667    0.032530       0.033830    0.024752    0.030094   \n",
       "1051           0.294118    0.031919       0.035692    0.019466    0.034863   \n",
       "16312          0.607843    0.113739       0.144010    0.076112    0.145206   \n",
       "2042           0.431373    0.053283       0.059590    0.031789    0.066436   \n",
       "1755           0.882353    0.048298       0.045624    0.029059    0.057721   \n",
       "16022          1.000000    0.061015       0.053538    0.028323    0.053774   \n",
       "20441          0.450980    0.103515       0.090161    0.064104    0.092748   \n",
       "13243          0.156863    0.098555       0.075885    0.063439    0.080414   \n",
       "6450           0.843137    0.050994       0.044538    0.032139    0.050321   \n",
       "10229          0.686275    0.023628       0.043141    0.027133    0.049663   \n",
       "6463           0.823529    0.046569       0.054935    0.027413    0.054761   \n",
       "183            0.960784    0.044356       0.074333    0.040122    0.068081   \n",
       "303            0.509804    0.023068       0.036468    0.013759    0.025654   \n",
       "1042           0.333333    0.070934       0.076195    0.041452    0.071863   \n",
       "14741          0.313725    0.069230       0.087834    0.077373    0.090939   \n",
       "18381          0.333333    0.027417       0.018777    0.013269    0.019734   \n",
       "2443           0.411765    0.045577       0.067349    0.039352    0.058872   \n",
       "7641           0.549020    0.070019       0.078678    0.071526    0.080086   \n",
       "517            1.000000    0.040923       0.031347    0.019361    0.029272   \n",
       "15465          0.235294    0.108627       0.137337    0.081399    0.131557   \n",
       "14309          0.666667    0.015565       0.027778    0.024087    0.026805   \n",
       "1477           0.392157    0.163869       0.285227    0.126667    0.285150   \n",
       "17197          0.529412    0.050435       0.090161    0.038126    0.089952   \n",
       "2895           0.666667    0.020932       0.027623    0.023352    0.029600   \n",
       "15638          1.000000    0.091459       0.156735    0.072086    0.158691   \n",
       "18035          0.509804    0.032123       0.033364    0.023002    0.037987   \n",
       "18295          0.588235    0.059871       0.062694    0.032139    0.058707   \n",
       "...                 ...         ...            ...         ...         ...   \n",
       "3748           0.803922    0.033216       0.044693    0.033155    0.049498   \n",
       "7742           0.470588    0.084923       0.122284    0.058887    0.123335   \n",
       "6383           0.686275    0.099344       0.113439    0.058992    0.119059   \n",
       "11721          0.352941    0.044356       0.047331    0.008683    0.016938   \n",
       "8535           0.411765    0.028613       0.044382    0.024297    0.039467   \n",
       "20191          0.196078    0.119360       0.148045    0.072191    0.161322   \n",
       "15436          0.352941    0.111857       0.128336    0.066450    0.120704   \n",
       "12170          0.333333    0.122005       0.160459    0.068725    0.155073   \n",
       "5758           0.411765    0.067704       0.100869    0.054266    0.103272   \n",
       "18707          0.764706    0.099013       0.144010    0.062283    0.149482   \n",
       "17657          0.666667    0.061448       0.058038    0.034485    0.061339   \n",
       "9772           0.431373    0.053233       0.083023    0.064944    0.074988   \n",
       "18491          0.294118    0.079302       0.106145    0.083325    0.111824   \n",
       "19315          0.352941    0.050003       0.054159    0.029724    0.050485   \n",
       "1949           0.274510    0.038939       0.046400    0.023492    0.047032   \n",
       "12911          0.588235    0.079149       0.066574    0.039142    0.074823   \n",
       "49             0.764706    0.024009       0.058038    0.024402    0.057721   \n",
       "19566          0.431373    0.088891       0.137492    0.086265    0.134024   \n",
       "13020          0.431373    0.046823       0.042210    0.028533    0.045223   \n",
       "6460           0.686275    0.040796       0.049193    0.031019    0.048183   \n",
       "2623           0.431373    0.053436       0.063625    0.035570    0.063476   \n",
       "17357          0.392157    0.054148       0.050900    0.038196    0.057885   \n",
       "20463          0.372549    0.088840       0.069522    0.056927    0.070219   \n",
       "12363          0.039216    0.233150       0.234482    0.134265    0.208683   \n",
       "16983          0.686275    0.020423       0.021570    0.015475    0.022694   \n",
       "5695           0.647059    0.061524       0.073557    0.043028    0.074494   \n",
       "8006           0.686275    0.024264       0.024519    0.014459    0.025654   \n",
       "17745          0.098039    0.089628       0.086592    0.048139    0.080579   \n",
       "17931          0.686275    0.021110       0.032588    0.018976    0.034534   \n",
       "13151          0.431373    0.085381       0.112353    0.065084    0.106890   \n",
       "\n",
       "       medianIncome  \n",
       "6761       0.142508  \n",
       "3010       0.045027  \n",
       "7812       0.212866  \n",
       "8480       0.298651  \n",
       "1051       0.272631  \n",
       "16312      0.192342  \n",
       "2042       0.207783  \n",
       "1755       0.346181  \n",
       "16022      0.436704  \n",
       "20441      0.382671  \n",
       "13243      0.550613  \n",
       "6450       0.420615  \n",
       "10229      0.148715  \n",
       "6463       0.212149  \n",
       "183        0.120695  \n",
       "303        0.108874  \n",
       "1042       0.190273  \n",
       "14741      0.231238  \n",
       "18381      0.591723  \n",
       "2443       0.052744  \n",
       "7641       0.324375  \n",
       "517        0.568806  \n",
       "15465      0.196170  \n",
       "14309      0.082440  \n",
       "1477       0.143736  \n",
       "17197      0.135874  \n",
       "2895       0.045786  \n",
       "15638      0.171529  \n",
       "18035      0.337319  \n",
       "18295      0.449966  \n",
       "...             ...  \n",
       "3748       0.154343  \n",
       "7742       0.220252  \n",
       "6383       0.280175  \n",
       "11721      0.297810  \n",
       "8535       0.199804  \n",
       "20191      0.187301  \n",
       "15436      0.216383  \n",
       "12170      0.111605  \n",
       "5758       0.216238  \n",
       "18707      0.057447  \n",
       "17657      0.385767  \n",
       "9772       0.176163  \n",
       "18491      0.210701  \n",
       "19315      0.287624  \n",
       "1949       0.142246  \n",
       "12911      0.396139  \n",
       "49         0.087937  \n",
       "19566      0.099619  \n",
       "13020      0.273762  \n",
       "6460       0.296079  \n",
       "2623       0.171805  \n",
       "17357      0.287231  \n",
       "20463      0.366181  \n",
       "12363      0.262838  \n",
       "16983      0.367043  \n",
       "5695       0.288637  \n",
       "8006       0.285720  \n",
       "17745      0.389402  \n",
       "17931      0.191818  \n",
       "13151      0.149791  \n",
       "\n",
       "[14448 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(data=scaler.transform(X_train),columns = X_train.columns,index=X_train.index)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(data=scaler.transform(X_test),columns = X_test.columns,index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome', 'medianHouseValue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnleonard/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train ,batch_size=10,num_epochs=1000,\n",
    "                                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.estimator.inputs.pandas_io.pandas_input_fn.<locals>.input_fn()>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/dk/jmp2jdj96xd00z6w7mbmgvh40000gn/T/tmpygx8jesm\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/dk/jmp2jdj96xd00z6w7mbmgvh40000gn/T/tmpygx8jesm', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2cbecd30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(hidden_units=[6,6,6],feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\Marcial\\AppData\\Local\\Temp\\tmp244d0d44\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 5.68896e+11\n",
      "INFO:tensorflow:global_step/sec: 581.528\n",
      "INFO:tensorflow:step = 101, loss = 5.52951e+11 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.865\n",
      "INFO:tensorflow:step = 201, loss = 5.91057e+11 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.467\n",
      "INFO:tensorflow:step = 301, loss = 5.48503e+11 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.11\n",
      "INFO:tensorflow:step = 401, loss = 1.96651e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.59\n",
      "INFO:tensorflow:step = 501, loss = 3.18206e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.779\n",
      "INFO:tensorflow:step = 601, loss = 7.34722e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.111\n",
      "INFO:tensorflow:step = 701, loss = 6.52219e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.376\n",
      "INFO:tensorflow:step = 801, loss = 1.67628e+11 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.426\n",
      "INFO:tensorflow:step = 901, loss = 3.40569e+11 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.466\n",
      "INFO:tensorflow:step = 1001, loss = 1.4957e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.166\n",
      "INFO:tensorflow:step = 1101, loss = 2.99765e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.109\n",
      "INFO:tensorflow:step = 1201, loss = 1.18134e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.463\n",
      "INFO:tensorflow:step = 1301, loss = 4.19775e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 1401, loss = 9.50937e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.782\n",
      "INFO:tensorflow:step = 1501, loss = 7.97535e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.823\n",
      "INFO:tensorflow:step = 1601, loss = 7.43758e+10 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.308\n",
      "INFO:tensorflow:step = 1701, loss = 4.21438e+10 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 602.625\n",
      "INFO:tensorflow:step = 1801, loss = 2.94767e+11 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.358\n",
      "INFO:tensorflow:step = 1901, loss = 9.65828e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.163\n",
      "INFO:tensorflow:step = 2001, loss = 9.45288e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.119\n",
      "INFO:tensorflow:step = 2101, loss = 6.37785e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.769\n",
      "INFO:tensorflow:step = 2201, loss = 7.37902e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 2301, loss = 6.8529e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.463\n",
      "INFO:tensorflow:step = 2401, loss = 2.60072e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 2501, loss = 4.08405e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.109\n",
      "INFO:tensorflow:step = 2601, loss = 8.2585e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.398\n",
      "INFO:tensorflow:step = 2701, loss = 1.93861e+11 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.143\n",
      "INFO:tensorflow:step = 2801, loss = 1.22862e+11 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.092\n",
      "INFO:tensorflow:step = 2901, loss = 1.07041e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.783\n",
      "INFO:tensorflow:step = 3001, loss = 8.10357e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.853\n",
      "INFO:tensorflow:step = 3101, loss = 1.04205e+11 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.462\n",
      "INFO:tensorflow:step = 3201, loss = 1.15509e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.898\n",
      "INFO:tensorflow:step = 3301, loss = 1.22119e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.608\n",
      "INFO:tensorflow:step = 3401, loss = 1.31626e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.782\n",
      "INFO:tensorflow:step = 3501, loss = 7.18527e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.397\n",
      "INFO:tensorflow:step = 3601, loss = 1.46789e+11 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.601\n",
      "INFO:tensorflow:step = 3701, loss = 8.47148e+10 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.355\n",
      "INFO:tensorflow:step = 3801, loss = 1.62093e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.111\n",
      "INFO:tensorflow:step = 3901, loss = 1.00475e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.164\n",
      "INFO:tensorflow:step = 4001, loss = 1.29159e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.161\n",
      "INFO:tensorflow:step = 4101, loss = 2.17452e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.505\n",
      "INFO:tensorflow:step = 4201, loss = 2.42384e+11 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.298\n",
      "INFO:tensorflow:step = 4301, loss = 4.4548e+10 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.353\n",
      "INFO:tensorflow:step = 4401, loss = 6.80362e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.646\n",
      "INFO:tensorflow:step = 4501, loss = 1.11679e+11 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.358\n",
      "INFO:tensorflow:step = 4601, loss = 6.4636e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 4701, loss = 5.27234e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.893\n",
      "INFO:tensorflow:step = 4801, loss = 1.23856e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 4901, loss = 7.06492e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.161\n",
      "INFO:tensorflow:step = 5001, loss = 6.72092e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.891\n",
      "INFO:tensorflow:step = 5101, loss = 6.41032e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.354\n",
      "INFO:tensorflow:step = 5201, loss = 5.71987e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.12\n",
      "INFO:tensorflow:step = 5301, loss = 7.72789e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.144\n",
      "INFO:tensorflow:step = 5401, loss = 6.75083e+10 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.683\n",
      "INFO:tensorflow:step = 5501, loss = 1.74011e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.462\n",
      "INFO:tensorflow:step = 5601, loss = 1.5761e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.118\n",
      "INFO:tensorflow:step = 5701, loss = 4.77042e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 5801, loss = 9.11984e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.894\n",
      "INFO:tensorflow:step = 5901, loss = 8.06788e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.116\n",
      "INFO:tensorflow:step = 6001, loss = 1.09098e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.141\n",
      "INFO:tensorflow:step = 6101, loss = 5.64201e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.49\n",
      "INFO:tensorflow:step = 6201, loss = 7.46827e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.995\n",
      "INFO:tensorflow:step = 6301, loss = 2.63389e+11 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.492\n",
      "INFO:tensorflow:step = 6401, loss = 1.11202e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.662\n",
      "INFO:tensorflow:step = 6501, loss = 3.25186e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.166\n",
      "INFO:tensorflow:step = 6601, loss = 5.04853e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 6701, loss = 1.11964e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.358\n",
      "INFO:tensorflow:step = 6801, loss = 8.67505e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.311\n",
      "INFO:tensorflow:step = 6901, loss = 1.49481e+11 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.356\n",
      "INFO:tensorflow:step = 7001, loss = 1.10759e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.339\n",
      "INFO:tensorflow:step = 7101, loss = 1.36751e+11 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.287\n",
      "INFO:tensorflow:step = 7201, loss = 3.93489e+10 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.609\n",
      "INFO:tensorflow:step = 7301, loss = 2.62178e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.132\n",
      "INFO:tensorflow:step = 7401, loss = 5.60514e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.938\n",
      "INFO:tensorflow:step = 7501, loss = 6.14047e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.166\n",
      "INFO:tensorflow:step = 7601, loss = 1.1274e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 7701, loss = 1.3928e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.611\n",
      "INFO:tensorflow:step = 7801, loss = 5.88718e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.894\n",
      "INFO:tensorflow:step = 7901, loss = 1.05752e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.528\n",
      "INFO:tensorflow:step = 8001, loss = 8.99248e+10 (0.155 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 619.468\n",
      "INFO:tensorflow:step = 8101, loss = 6.23952e+10 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.164\n",
      "INFO:tensorflow:step = 8201, loss = 1.45558e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.117\n",
      "INFO:tensorflow:step = 8301, loss = 5.34845e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.821\n",
      "INFO:tensorflow:step = 8401, loss = 8.33874e+10 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.836\n",
      "INFO:tensorflow:step = 8501, loss = 1.16478e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.109\n",
      "INFO:tensorflow:step = 8601, loss = 1.72198e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.163\n",
      "INFO:tensorflow:step = 8701, loss = 1.35063e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 674.01\n",
      "INFO:tensorflow:step = 8801, loss = 1.63489e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.32\n",
      "INFO:tensorflow:step = 8901, loss = 9.24273e+10 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.281\n",
      "INFO:tensorflow:step = 9001, loss = 1.02409e+11 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 9101, loss = 8.10587e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 9201, loss = 1.55986e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.458\n",
      "INFO:tensorflow:step = 9301, loss = 5.02188e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.465\n",
      "INFO:tensorflow:step = 9401, loss = 2.5209e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.165\n",
      "INFO:tensorflow:step = 9501, loss = 5.85972e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.457\n",
      "INFO:tensorflow:step = 9601, loss = 2.1635e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.459\n",
      "INFO:tensorflow:step = 9701, loss = 1.35898e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.237\n",
      "INFO:tensorflow:step = 9801, loss = 1.25752e+11 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.491\n",
      "INFO:tensorflow:step = 9901, loss = 5.87676e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.11\n",
      "INFO:tensorflow:step = 10001, loss = 9.59187e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.597\n",
      "INFO:tensorflow:step = 10101, loss = 6.46078e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.357\n",
      "INFO:tensorflow:step = 10201, loss = 9.63727e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.365\n",
      "INFO:tensorflow:step = 10301, loss = 1.95255e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.594\n",
      "INFO:tensorflow:step = 10401, loss = 1.04688e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.116\n",
      "INFO:tensorflow:step = 10501, loss = 4.65059e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.775\n",
      "INFO:tensorflow:step = 10601, loss = 9.29294e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.26\n",
      "INFO:tensorflow:step = 10701, loss = 5.7327e+10 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.687\n",
      "INFO:tensorflow:step = 10801, loss = 1.20981e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.117\n",
      "INFO:tensorflow:step = 10901, loss = 1.37803e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.131\n",
      "INFO:tensorflow:step = 11001, loss = 8.51191e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.152\n",
      "INFO:tensorflow:step = 11101, loss = 3.58583e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.879\n",
      "INFO:tensorflow:step = 11201, loss = 1.79992e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.877\n",
      "INFO:tensorflow:step = 11301, loss = 5.87205e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.36\n",
      "INFO:tensorflow:step = 11401, loss = 3.06918e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.611\n",
      "INFO:tensorflow:step = 11501, loss = 1.39031e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.64\n",
      "INFO:tensorflow:step = 11601, loss = 1.33908e+11 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.665\n",
      "INFO:tensorflow:step = 11701, loss = 5.29911e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.358\n",
      "INFO:tensorflow:step = 11801, loss = 4.43427e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.459\n",
      "INFO:tensorflow:step = 11901, loss = 1.27809e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.354\n",
      "INFO:tensorflow:step = 12001, loss = 1.09418e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.461\n",
      "INFO:tensorflow:step = 12101, loss = 1.19023e+11 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.855\n",
      "INFO:tensorflow:step = 12201, loss = 6.26613e+10 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.161\n",
      "INFO:tensorflow:step = 12301, loss = 5.95497e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.896\n",
      "INFO:tensorflow:step = 12401, loss = 7.19391e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.644\n",
      "INFO:tensorflow:step = 12501, loss = 1.39082e+11 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.117\n",
      "INFO:tensorflow:step = 12601, loss = 1.07392e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.78\n",
      "INFO:tensorflow:step = 12701, loss = 5.54437e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.118\n",
      "INFO:tensorflow:step = 12801, loss = 1.71102e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.88\n",
      "INFO:tensorflow:step = 12901, loss = 1.31806e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.118\n",
      "INFO:tensorflow:step = 13001, loss = 7.74501e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.112\n",
      "INFO:tensorflow:step = 13101, loss = 1.0411e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.882\n",
      "INFO:tensorflow:step = 13201, loss = 1.39836e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.684\n",
      "INFO:tensorflow:step = 13301, loss = 5.82197e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.867\n",
      "INFO:tensorflow:step = 13401, loss = 1.33974e+11 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.879\n",
      "INFO:tensorflow:step = 13501, loss = 8.2805e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.119\n",
      "INFO:tensorflow:step = 13601, loss = 1.43746e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.609\n",
      "INFO:tensorflow:step = 13701, loss = 7.63106e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.341\n",
      "INFO:tensorflow:step = 13801, loss = 1.13861e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.599\n",
      "INFO:tensorflow:step = 13901, loss = 4.34979e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.895\n",
      "INFO:tensorflow:step = 14001, loss = 9.24518e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.866\n",
      "INFO:tensorflow:step = 14101, loss = 3.88536e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.982\n",
      "INFO:tensorflow:step = 14201, loss = 1.44936e+11 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.984\n",
      "INFO:tensorflow:step = 14301, loss = 6.60796e+10 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.88\n",
      "INFO:tensorflow:step = 14401, loss = 4.83868e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.087\n",
      "INFO:tensorflow:step = 14501, loss = 7.28641e+10 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.483\n",
      "INFO:tensorflow:step = 14601, loss = 8.52518e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.49\n",
      "INFO:tensorflow:step = 14701, loss = 4.43568e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.88\n",
      "INFO:tensorflow:step = 14801, loss = 8.06209e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 14901, loss = 1.04303e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 15001, loss = 1.22773e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.276\n",
      "INFO:tensorflow:step = 15101, loss = 5.41949e+10 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.282\n",
      "INFO:tensorflow:step = 15201, loss = 6.49725e+10 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.609\n",
      "INFO:tensorflow:step = 15301, loss = 1.12484e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.103\n",
      "INFO:tensorflow:step = 15401, loss = 2.62009e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.161\n",
      "INFO:tensorflow:step = 15501, loss = 6.38702e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.564\n",
      "INFO:tensorflow:step = 15601, loss = 1.30054e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.458\n",
      "INFO:tensorflow:step = 15701, loss = 1.26559e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.467\n",
      "INFO:tensorflow:step = 15801, loss = 6.27563e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.116\n",
      "INFO:tensorflow:step = 15901, loss = 3.63661e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.293\n",
      "INFO:tensorflow:step = 16001, loss = 1.10022e+11 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.735\n",
      "INFO:tensorflow:step = 16101, loss = 1.28868e+11 (0.154 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 660.481\n",
      "INFO:tensorflow:step = 16201, loss = 3.05991e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.456\n",
      "INFO:tensorflow:step = 16301, loss = 1.88008e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.115\n",
      "INFO:tensorflow:step = 16401, loss = 1.83709e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.163\n",
      "INFO:tensorflow:step = 16501, loss = 1.30615e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.163\n",
      "INFO:tensorflow:step = 16601, loss = 1.21363e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.686\n",
      "INFO:tensorflow:step = 16701, loss = 5.79005e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.164\n",
      "INFO:tensorflow:step = 16801, loss = 2.05555e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.28\n",
      "INFO:tensorflow:step = 16901, loss = 1.13958e+11 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.145\n",
      "INFO:tensorflow:step = 17001, loss = 1.56865e+11 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.463\n",
      "INFO:tensorflow:step = 17101, loss = 1.03525e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.119\n",
      "INFO:tensorflow:step = 17201, loss = 1.24523e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.779\n",
      "INFO:tensorflow:step = 17301, loss = 5.34006e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.151\n",
      "INFO:tensorflow:step = 17401, loss = 1.2656e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.369\n",
      "INFO:tensorflow:step = 17501, loss = 6.63956e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.458\n",
      "INFO:tensorflow:step = 17601, loss = 1.41557e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.611\n",
      "INFO:tensorflow:step = 17701, loss = 6.71941e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.548\n",
      "INFO:tensorflow:step = 17801, loss = 9.65344e+10 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.091\n",
      "INFO:tensorflow:step = 17901, loss = 7.02002e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.466\n",
      "INFO:tensorflow:step = 18001, loss = 8.1741e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 18101, loss = 8.89474e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.877\n",
      "INFO:tensorflow:step = 18201, loss = 9.00486e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.167\n",
      "INFO:tensorflow:step = 18301, loss = 1.31469e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.118\n",
      "INFO:tensorflow:step = 18401, loss = 7.92592e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.165\n",
      "INFO:tensorflow:step = 18501, loss = 9.01399e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.686\n",
      "INFO:tensorflow:step = 18601, loss = 1.3865e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.641\n",
      "INFO:tensorflow:step = 18701, loss = 1.03642e+11 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 18801, loss = 1.34628e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.602\n",
      "INFO:tensorflow:step = 18901, loss = 1.15692e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.61\n",
      "INFO:tensorflow:step = 19001, loss = 4.5566e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.781\n",
      "INFO:tensorflow:step = 19101, loss = 8.53202e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.097\n",
      "INFO:tensorflow:step = 19201, loss = 1.75635e+11 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.352\n",
      "INFO:tensorflow:step = 19301, loss = 1.45976e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.111\n",
      "INFO:tensorflow:step = 19401, loss = 8.82003e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.53\n",
      "INFO:tensorflow:step = 19501, loss = 5.50821e+10 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.465\n",
      "INFO:tensorflow:step = 19601, loss = 7.29649e+10 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.781\n",
      "INFO:tensorflow:step = 19701, loss = 1.03718e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.465\n",
      "INFO:tensorflow:step = 19801, loss = 9.0983e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.88\n",
      "INFO:tensorflow:step = 19901, loss = 6.34958e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.593\n",
      "INFO:tensorflow:step = 20001, loss = 7.29011e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.463\n",
      "INFO:tensorflow:step = 20101, loss = 7.10435e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.08\n",
      "INFO:tensorflow:step = 20201, loss = 3.92134e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.356\n",
      "INFO:tensorflow:step = 20301, loss = 8.98195e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.993\n",
      "INFO:tensorflow:step = 20401, loss = 1.09406e+11 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.339\n",
      "INFO:tensorflow:step = 20501, loss = 2.47776e+11 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.611\n",
      "INFO:tensorflow:step = 20601, loss = 1.17861e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 20701, loss = 1.22166e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.463\n",
      "INFO:tensorflow:step = 20801, loss = 8.55185e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.118\n",
      "INFO:tensorflow:step = 20901, loss = 8.71972e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.88\n",
      "INFO:tensorflow:step = 21001, loss = 5.74192e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.464\n",
      "INFO:tensorflow:step = 21101, loss = 1.38993e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.357\n",
      "INFO:tensorflow:step = 21201, loss = 1.19078e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.235\n",
      "INFO:tensorflow:step = 21301, loss = 4.69408e+10 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.324\n",
      "INFO:tensorflow:step = 21401, loss = 8.83013e+10 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.612\n",
      "INFO:tensorflow:step = 21501, loss = 1.1924e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.101\n",
      "INFO:tensorflow:step = 21601, loss = 5.66231e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.117\n",
      "INFO:tensorflow:step = 21701, loss = 1.924e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 671.614\n",
      "INFO:tensorflow:step = 21801, loss = 6.78586e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.876\n",
      "INFO:tensorflow:step = 21901, loss = 1.24602e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.465\n",
      "INFO:tensorflow:step = 22001, loss = 1.64181e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.113\n",
      "INFO:tensorflow:step = 22101, loss = 8.47417e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.465\n",
      "INFO:tensorflow:step = 22201, loss = 6.85675e+10 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.447\n",
      "INFO:tensorflow:step = 22301, loss = 7.44498e+10 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.298\n",
      "INFO:tensorflow:step = 22401, loss = 7.87e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.343\n",
      "INFO:tensorflow:step = 22501, loss = 1.11396e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.355\n",
      "INFO:tensorflow:step = 22601, loss = 5.56336e+10 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.88\n",
      "INFO:tensorflow:step = 22701, loss = 1.38838e+11 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.879\n",
      "INFO:tensorflow:step = 22801, loss = 1.20702e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.739\n",
      "INFO:tensorflow:step = 22901, loss = 1.34259e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 23001, loss = 7.11723e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.749\n",
      "INFO:tensorflow:step = 23101, loss = 7.58483e+10 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 660.491\n",
      "INFO:tensorflow:step = 23201, loss = 1.92337e+11 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.896\n",
      "INFO:tensorflow:step = 23301, loss = 7.07594e+10 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.878\n",
      "INFO:tensorflow:step = 23401, loss = 5.36163e+10 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.879\n",
      "INFO:tensorflow:step = 23501, loss = 1.48012e+11 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.114\n",
      "INFO:tensorflow:step = 23601, loss = 1.19497e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.898\n",
      "INFO:tensorflow:step = 23701, loss = 1.90323e+11 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 678.465\n",
      "INFO:tensorflow:step = 23801, loss = 3.08241e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.856\n",
      "INFO:tensorflow:step = 23901, loss = 8.0755e+10 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.287\n",
      "INFO:tensorflow:step = 24001, loss = 4.11171e+10 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.993\n",
      "INFO:tensorflow:step = 24101, loss = 1.44191e+11 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.898\n",
      "INFO:tensorflow:step = 24201, loss = 7.857e+10 (0.151 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 651.856\n",
      "INFO:tensorflow:step = 24301, loss = 7.52043e+10 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 676.164\n",
      "INFO:tensorflow:step = 24401, loss = 1.08424e+11 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.356\n",
      "INFO:tensorflow:step = 24501, loss = 9.23162e+10 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.779\n",
      "INFO:tensorflow:step = 24601, loss = 5.40436e+10 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 683.097\n",
      "INFO:tensorflow:step = 24701, loss = 8.55543e+10 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.971\n",
      "INFO:tensorflow:step = 24801, loss = 1.211e+11 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.241\n",
      "INFO:tensorflow:step = 24901, loss = 6.22166e+10 (0.159 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 25000 into C:\\Users\\Marcial\\AppData\\Local\\Temp\\tmp244d0d44\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.48849e+10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x21cd41ab048>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gen = model.predict(predict_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Could not find trained model in model_dir: /var/folders/dk/jmp2jdj96xd00z6w7mbmgvh40000gn/T/tmpygx8jesm, running initialization to predict.\n",
      "WARNING:tensorflow:From /Users/johnleonard/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/johnleonard/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/johnleonard/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(pred_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in predictions:\n",
    "    final_preds.append(pred['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97921.93181985477"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,final_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
